library(caret);
setwd("D:/R")
install.packages("caret")
install.packages("kernlab")
library(caret);
library(kernlab);
data(spam)
spam
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
dim(training)
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
library(stats);
modelFit <- train(type ~.,data=training, method="glm")
install.packages('e1071', dependencies=TRUE)
getwd()
library("e1071", lib.loc="D:/R-3.2.0/library")
modelFit <- train(type ~.,data=training, method="glm")
modelFit
modelFit$finalModel
summary(modelFit$finalModel)
predictions <- predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
spam
library(caret);
library(kernlab);
data(spam)
spam
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds[[1]][1:10]
set.seed(32323)
folds <- createResample(y=spam$type,times=10,list=TRUE)
sapply(folds,length)
folds[[1]][1:10]
set.seed(32323)
tme <- 1:1000
folds <- createTimeSlices(y=tme,initialWindow=20,horizon=10)
names(folds)
folds$train[[1]]
folds$test[[1]]
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library(caret);
library(kernlab);
data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~.,data=training, method="glm")
set.seed(1235)
modelFit3 <- train(type ~.,data=training, method="glm")
modelFit3 <- train(type ~.,data=training, method="glm")
modelFit3
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library(ISLR)
install.packages("islr")
install.packages("ISLR")
library("ISLR", lib.loc="D:/R-3.2.0/library")
library("ggplot2", lib.loc="D:/R-3.2.0/library")
library("caret", lib.loc="D:/R-3.2.0/library")
data(Wage)
summary(Wage)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library("caret", lib.loc="D:/R-3.2.0/library")
library("kernlab", lib.loc="D:/R-3.2.0/library")
data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~.,data=training,preProcess=c("center","scale"),method="glm")
modelFit
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
install.packages("RANN")
library("RANN", lib.loc="D:/R-3.2.0/library")
capAve <- predict(preObj,training[,-58])$capAve
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library(caret);
library(kernlab);
data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
names(spam)[c(34,32,40)]
plot(spam[,34],spam[,32])
plot(spam[,34],spam[,40])
plot(spam[,32],spam[,40])
plot(spam[,32],spam[,40])
plot(spam[,34],spam[,40])
X=0.71×num415+0.71×num857
X=0.71*num415+0.71*num857
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
smallSpam1 <- spam[,c(34,32,40)]
prComp1 <- prcomp(smallSpam1)
plot(prComp1$x[,1],prComp1$x[,2])
plot(prComp1$x[,1],prComp1$x[,3])
plot(prComp1$x[,2],prComp1$x[,3])
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library(caret);data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]head(trainFaith)
trainFaith <- faithful[inTrain,];
testFaith <- faithful[-inTrain,]head(trainFaith)
testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library(ISLR); library(ggplot2); library(caret);
data(Wage);
Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training);
dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y = training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
modFit<- train(wage ~ age + jobclass + education,method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
plot(finMod$residuals,pch=19)
plot(finMod$residuals,pch=19)
pred <- predict(modFit, testing)
qplot(wage,pred,colour=year,data=testing)
pred <- predict(modFitAll, testing)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
savehistory("D:/R/Regressionc.Rhistory")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling", lib.loc="D:/R-3.2.0/library")
library("caret", lib.loc="D:/R-3.2.0/library")
data(AlzheimerDisease)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer)
hist(training$Superplasticizer)
hist(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
nTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ola <- grep( "^IL", names(training), value=TRUE)
small_data_set <- subset(training, select=ola)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
training1 = read.csv(pml-training, header = TRUE)
training1 = read.csv(pml-training.csv, header = TRUE)
training1 = read.csv("pml-training.csv"", header = TRUE)
,,,,,,,,,,
read.csv
,fdkoai9udqwqpdlmmjjf
mmmmmm
training1 = read.csv("pml-training.csv"", header = TRUE)
training1 = read.csv("pml-training.csv"", header = TRUE)
training1 = read.csv("pml-training.csv"", header = TRUE)
training1 = read.csv("pml-training.csv", header = TRUE)
training1 = read.csv("pml-training.csv", header = TRUE)
training1 = read.csv("pml-training.csv")
training1 = read.csv2("pml-training.csv")
getwd()
training1 = read.csv("pml-training.csv", header = T)
training1 = read.csv("D:\R\Machine learning\pml-training.csv", header = T)
training1 = read.csv("D:\\R\\Machine learning\\pml-training.csv", header = T)
training1
getwd()
summary(training1)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
training1 = read.csv("D:\R\Machine learning\pml-training.csv", header = T)
training1 = read.csv("D:\\R\\Machine learning\\pml-training.csv", header = T)
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
library("caret", lib.loc="D:/R-3.2.0/library")
inTrain <- createDataPartition(y=training1,p=0.7, list=FALSE)
qplot(accel_belt_y,magnet_belt_y,data=training1)
home1 = qplot(accel_belt_y,magnet_belt_y,data=training1)
q1 = qplot(accel_belt_y,magnet_belt_y,data=training1)
q2 = qplot(accel_belt_y,magnet_belt_y,colour = classe, data=training1)
q2
q3 = q2 + geom_smooth(method = 'lm', formula = y~x)
q3
lr1 = train(y ~ ., data=training1, method="glm")
lr1 = train(classe ~ ., data=training1, method="glm")
lr1 = train(classe ~ ., data=training1, method="glm")
lr2 = train(classe ~ ., preProcess="pca", data=training1, method="glm")
lr2 = train(classe ~ ., method="glm", preProcess="pca", data=training1)
lr2 = train(training1$classe ~ ., method="glm", preProcess="pca", data=training1)
levels(classe)
levels(training1$classe)
lr2 = train(factor(classe) ~ ., method="glm", preProcess="pca", data=training1)
str(trainData$classe)
str(training1$classe)
lr2 = train(as.factor(classe) ~ ., method="glm", preProcess="pca", data=training1)
lr2 = train(as.factor(classe) ~ ., method="glm", preProcess=c("center", "scale"), preProcess="pca", data=training1)
lr2 = train(as.factor(classe) ~ ., method="glm", preProcess=c("center", "scale"), data=training1)
lr2 = train(as.factor(classe) ~ ., method="glm", preProcess=c("center", "scale"), na.remove = TRUE, data=training1)
lr2 = train(classe ~ ., method="glm", preProcess=c("center", "scale"), na.remove = TRUE, data=training1)
lr2 = train(classe ~ ., method="glm", preProcess=c("center", "scale"), na.action = TRUE, data=training1)
fit <- prcomp(t(training1))
library("nnet", lib.loc="D:/R-3.2.0/library")
lr2 = train(classe ~ ., method="multinom", preProcess=c("center", "scale"), na.action = TRUE, data=training1)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
training.csv <- training.csv1[training1.csv$new_window =='no',]
training.csv <- training1.csv[training1.csv$new_window =='no',]
inTrain <- createDataPartition(training.csv1$classe, p = 0.70)[[1]]
inTrain <- createDataPartition(training1.csv$classe, p = 0.70)[[1]]
training1 = read.csv("D:\\R\\Machine learning\\pml-training.csv", header = T)
inTrain <- createDataPartition(training1$classe, p = 0.70)[[1]]
training2 <- training1[training1.$new_window =='no',]
training2 <- training1[training1$new_window =='no',]
inTrain <- createDataPartition(training1$classe, p = 0.70)[[1]]
training <- training1[inTrain,]
testing <- training1[-inTrain,]
colnames.predicting <- c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x', 'accel_belt_y', 'accel_belt_z','magnet_belt_y', 'magnet_belt_x', 'magnet_belt_z','roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm','gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z'), 'accel_arm_x', 'accel_arm_y', 'accel_arm_z','magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z','roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y', 'gyros_dumbbell_z','accel_dumbbell_x', 'accel_dumbbell_y', 'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y', 'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm', 'total_accel_forearm','gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y', 'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y', 'magnet_forearm_z')
colnames.predicting <- c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x', 'accel_belt_y', 'accel_belt_z','magnet_belt_y', 'magnet_belt_x', 'magnet_belt_z','roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm','gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z'), 'accel_arm_x', 'accel_arm_y', 'accel_arm_z','magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z','roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y', 'gyros_dumbbell_z','accel_dumbbell_x', 'accel_dumbbell_y', 'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y', 'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm', 'total_accel_forearm','gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y', 'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y', 'magnet_forearm_z')
savehistory("D:/R/MachineLearningWeek1.Rhistory")
colnames.predicting  = c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x', 'accel_belt_y', 'accel_belt_z','magnet_belt_y', 'magnet_belt_x', 'magnet_belt_z','roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm','gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z'), 'accel_arm_x', 'accel_arm_y', 'accel_arm_z','magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z','roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y', 'gyros_dumbbell_z','accel_dumbbell_x', 'accel_dumbbell_y', 'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y', 'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm', 'total_accel_forearm','gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y', 'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y', 'magnet_forearm_z')
colnames.predicting <- c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt')
colnames.predicting <- c(colnames.predicting, 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z')
colnames.predicting <- c(colnames.predicting, 'accel_belt_x', 'accel_belt_y', 'accel_belt_z')
colnames.predicting  = c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x', 'accel_belt_y', 'accel_belt_z','magnet_belt_y', 'magnet_belt_x', 'magnet_belt_z','roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm','gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z'), 'accel_arm_x', 'accel_arm_y', 'accel_arm_z','magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z','roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y', 'gyros_dumbbell_z','accel_dumbbell_x', 'accel_dumbbell_y', 'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y', 'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm', 'total_accel_forearm','gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y', 'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y', 'magnet_forearm_z')
colnames.predicting  = c('roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt', 'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x', 'accel_belt_y', 'accel_belt_z','magnet_belt_y', 'magnet_belt_x', 'magnet_belt_z','roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm','gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z'), 'accel_arm_x', 'accel_arm_y', 'accel_arm_z','magnet_arm_x', 'magnet_arm_y', 'magnet_arm_z','roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y', 'gyros_dumbbell_z','accel_dumbbell_x', 'accel_dumbbell_y', 'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y', 'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm', 'total_accel_forearm','gyros_forearm_x', 'gyros_forearm_y', 'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y', 'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y', 'magnet_forearm_z')
trainFeatures <- training[,7:159]
testFeatures <- testing[,7:159]
trainFeatures <- suppressWarnings(data.frame(sapply(trainFeatures, as.numeric)))
testFeatures <- suppressWarnings(data.frame(sapply(testFeatures, as.numeric)))
trainFeatures[is.na(trainFeatures)] <- 0
testFeatures[is.na(testFeatures)] <- 0
nearZero <- nearZeroVar(trainFeatures)
trainFeatures <- trainFeatures[,-nearZero]
testFeatures <- testFeatures[,-nearZero]
set.seed(123)
inTrain <- createDataPartition(training1$classe, p = 0.70)[[1]]
training <- trainFeatures[inTrain,]
testing <- trainFeatures[-inTrain,]
cor <- findCorrelation(cor(training))
ctrl <- trainControl(method = "repeatedcv", repeats = 5, number = 10)
ctrl
savehistory("D:/R/MachineLearningWeek1.Rhistory")
training1 = read.csv("D:\\R\\Machine learning\\pml-training.csv", header = T,stringsAsFactors = FALSE)
testing1 <- read.csv("D:\\R\\Machine learning\\pml-testing.csv", header = T, stringsAsFactors = FALSE)
training1variables <- training[,7:159]
training1variables <- training1[,7:159]
testing1variables <- testing1[,7:159]
training1variables <- suppressWarnings(data.frame(sapply(training1variables, as.numeric)))
testing1variable <- suppressWarnings(data.frame(sapply(testingvariables, as.numeric)))
testing1variable <- suppressWarnings(data.frame(sapply(testing1variables, as.numeric)))
training1variables[is.na(trainFeatures)] = 0  ## Change NA's to 0
training1variables[is.na(training1variables)] = 0  ## Change NA's to 0
testing1variables[is.na(testing1variables)] <- 0  ## Change NA's to 0
## Divide up pmlTraining data into a training and test set for testing our model
set.seed(123)
intrain <- createDataPartition(training1$classe, p = 0.70)[[1]]
library("caret", lib.loc="D:/R-3.2.0/library")
intrain <- createDataPartition(training1$classe, p = 0.70)[[1]]
training <- trainFeatures[intrain,]
training <- intrain[intrain,]
intrain <- createDataPartition(y= training1$classe, p = 0.70, list = FALSE)
intrain <- createDataPartition(y= training1variables$classe, p = 0.70, list = FALSE)
intrain <- createDataPartition(y= training1$classe, p = 0.70, list = FALSE)
set.seed(123)
intrain <- createDataPartition(y= training1$classe, p = 0.70, list = FALSE)
training = training1variables[intrain,]
testing = training1variables[-intrain,]
y = as.factor(training1$classe[intrain])
ytest = as.factor(training1$classe[-intrain])
savehistory("D:/R/MachineLearningWeek1.Rhistory")
cor <- findCorrelation(cor(training))
cor = findCorrelation(cor(training))
nearZeroVar(training, saveMetrics=TRUE)
modelFit <- train(training1$classe ~ .,method="glm",preProcess="pca",data=training)
modelFit <- train(training$classe ~ .,method="glm",preProcess="pca",data=training)
modelFit1 = train(classe ~ .,method="glm",preProcess="pca",data=training)
modelFit1 = train(classe ~ .,method="glm",data=training)
modelFit1 = train(training$classe ~ .,method="glm",data=training)
rf<-train(classe ~ ., data=training, method="rf", prox=TRUE, ntree=500)
rf<-train(y ~ ., data=training, method="rf", prox=TRUE, ntree=500)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
library("caret", lib.loc="D:/R-3.2.0/library")
training1 = read.csv("D:\\R\\Machine learning\\pml-training.csv", header = T, stringsAsFactors = FALSE)
testing1 = read.csv("D:\\R\\Machine learning\\pml-testing.csv", header = T, stringsAsFactors = FALSE)
trainfeatures = training[,7:159]
trainfeatures = training1[,7:159]
testFeatures <- testing1[,7:159]
trainfeatures <- suppressWarnings(data.frame(sapply(trainFeatures, as.numeric)))
trainfeatures <- suppressWarnings(data.frame(sapply(trainfeatures, as.numeric)))
testfeatures <- suppressWarnings(data.frame(sapply(testfeatures, as.numeric)))
testFeatures <- suppressWarnings(data.frame(sapply(testFeatures, as.numeric)))
trainfeatures[is.na(trainfeatures)] <- 0
testFeatures[is.na(testFeatures)] <- 0
nearZero <- nearZeroVar(trainfeatures)
trainfeatures <- trainfeatures[,-nearZero]
testFeatures <- testFeatures[,-nearZero]
set.seed(123)
intrain <- createDataPartition(y= training1$classe, p = 0.70, list = FALSE)
training = trainfeatures[intrain,]
testing = trainingfeatures[-intrain,]
testing = trainfeatures[-intrain,]
y = as.factor(training1$classe[intrain])
ytest = as.factor(training1$classe[-intrain])
cor <- findCorrelation(cor(training))
training <- training[,-cor]
testing <- testing[,-cor]
library("randomForest", lib.loc="D:/R-3.2.0/library")
prediction.model <- randomForest(classe ~ ., importance  = TRUE, data = training)
prediction.model <- randomForest(y ~ ., importance  = TRUE, data = training)
prediction.model
ncols(training)
ncol(training)
nrow(training)
importance(prediction.model)
savehistory("D:/R/MachineLearningWeek1.Rhistory")
